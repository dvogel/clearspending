{% extends "base.html" %}
{% block title %} <title>Clearspending.org - Results</title> {% endblock %}
{% block bodyclass %}analysis{% endblock %}
{% block content %}
<div id="pageMain">
    <div id="ltColumn">
        <h3>Results</h3>
        <p>Clearspending’s analysis consists of three metrics: consistency, completeness and timeliness. The consistency metric compares obligations reported in USASpending.gov with obligations reported in the Catalog of Federal Domestic Assistance (CFDA). Timeliness is a measure of how quickly those obligationd are reported. Completeness is a measurement of how many required fields were completed for each transaction reported to USASpending.gov. Together, these metrics speak to whether the information reported by agencies is consistent with figures reported elsewhere and whether the reporting is occurring in compliance with Office of Management and Budget policy and U.S. law.</p>
        <p>Clearspending’s scorecard allows users to view these metrics on an agency level and on a program level. For more information on how these metrics were calculated, please see our <a href="{% url methodology %}">methodology.</a></p>
        <p>Although our <a href="{% url scorecard-index %}">scorecard</a> provides a detailed view of each metric for every agency and program, here we present some aggregate figures that illustrate trends over the entire USASpending.gov dataset for the years 2008-2010.</p>
        <p>In the past three years there has been an increase in the number of programs reporting to USASpending.gov. However, the reported data suffers from an abundance of errors. There are also serious problems with the data’s timeliness and completeness. Previously, we reported that out of the total amount the government spent on grants in 2009, $1.3 trillion – 94% -- was incorrectly accounted for on USASpending.gov. Since that time, more late transactions have flowed into USASpending.gov, increasing the misreported percentage to 95.3%. For 2010, 94.5% of obligations failed at least one of our three metrics described above. These figures are summarized in the table below.</p>

        <h5 class="table-header">Failed Program Obligations By Fiscal Year</h5>
        <table class="results-table">
            <thead>
                <tr><th>Fiscal Year</th><th>Misreported Dollars</th><th>Total Dollars</th><th>% Misreported</th></tr>
            </thead>
            <tbody>
                <tr><td>2008</td><td>$1,789,074,455,301</td><td>$1,852,452,110,821</td><td>96.58%</td></tr>
                <tr class="even"><td>2009</td><td>$1,544,968,459,230</td><td>$1,621,109,941,736</td><td>95.30%</td></tr>
                <tr><td>2010</td><td>$1,306,120,795,761</td><td>$1,381,784,887,564</td><td>94.52%</td></tr>
            </tbody>
        </table>

        <p>The table above represents the total spending from failing programs out of the total value of all programs that reported data. We have seen no significant improvement in the quality of this data. As long as such a large portion of its data remains unreliable, USASpending.gov is not usable as a single source for any kind of analysis, whether by a citizen, media outlet or research institution.</p>

        <h4>Timeliness</h4>
        <p>The Federal Funding Accountability and Transparency Act (FFATA) requires that all federal spending be reported within 30 days of its obligation. For the purposes of our analysis, we use a window of 45 days. Note that we do not have comparison data for every transaction when measuring timeliness, only those presented in the raw agency submissions on USASpending.gov. As such, the following numbers are based on that sample (for more information on the makeup of this sample, see our <a href="{%url methodology%}">methodology</a>). Below are two tables, one showing the percentage of spending and the other showing the percentage of transactions that fail the timeliness metric. </p>
		<h5 class="table-header">Delay of Reported Obligations</h5>
		<table class="results-table">
            <thead>
    		    <tr><th>Fiscal Year</th><th>Spending in Sample Failing Timeliness</th><th>Total Spending in Sample</th><th>% Failed Timeliness</th></tr>
            </thead>
            <tbody>
    			<tr><td>2008</td><td>$251,958,897,554</td><td>$290,664,635,664</td><td>86.68%</td></tr>
	    		<tr class="even"><td>2009</td><td>$308,385,976,501</td><td>$437,348,451,504</td><td>70.51%</td></tr>
		    	<tr><td>2010</td><td>$41,287,268,187</td><td>$322,506,134,182</td><td>12.8%</td></tr>
            </tbody>
		</table>
        <h5 class="table-header">Transactions Reported Late by Fiscal Year</h5>
        <table class="results-table">
            <thead>
    		    <tr><th>Fiscal Year</th><th>Transactions in Sample Failing Timeliness</th><th>Total Transactions in Sample</th><th>% Failed Timeliness</th></tr>
            </thead>
            <tbody>
    			<tr><td>2008</td><td>157,462</td><td>207463</td><td>75.90%</td></tr>
	    		<tr class="even"><td>2009</td><td>69,912</td><td>287,834</td><td>24.20%</td></tr>
		    	<tr><td>2010</td><td>1532967</td><td>1815756</td><td>84.43%</td></tr>
            </tbody>
		</table>

<p>Between 2008 and 2010, the average delay between program obligation and reporting has decreased from 51 to 27 days. However, these improvements were not dispersed widely enough to bring the average agency reporting lag below the 30 days requirement as it has only fallen to 55 days.</p>
<p>The agencies with the worst record of being on time for FY 2010 are the Nuclear Regulatory Commission (100% late), the Export Import Bank of the United States (85%), and the Department of Homeland Security (82%). The agencies that were the most timely in FY 2010 were the Environmental Protection Agency (0%), the Department of Housing and Urban Development (1.6%) and the Department of Transportation (4.6%). </p>


        <h4>Consistency</h4>
       <p>A report by the Government Accountability Office (GAO) assessing USASpending.gov reported that 15 grant programs did not report any funding to USASpending.gov in 2008. Our analysis shows that this is a considerable underestimate. In fact, 327 programs did not report any spending to USASpending.gov for that year. For FY 2009 and FY 2010, there are also at least 300 programs that were not reporting. The total amount of the (non-reported) spending was $77 billion, or 5%, of the total grant spending for 2010. This is a significant drop from 12% in 2008 and 16% in 2009. </p>
        <p>In our last analysis, non-reported spending in FY 2008 was 22% of the overall total.  After re-running the analysis with updated data, it has dropped to 12%. We believe this is mostly due to several Medicare programs that retroactively reported spending to USASpending for 2007-2009. Coupled with the low percentage for 2010, this is a very positive trend. Several large programs have started reporting their spending consistently. However, the number of non-reporting programs has still not dropped below 300, suggesting that there is still a large core of programs (albeit with much lower annual obligations) that are completely divorced from the USASpending.gov reporting stream. In fact, 118 programs have not reported anything for all three years analyzed.</p> 

        <table class="results-table">
            <thead>
                <tr><th>Fiscal Year</th><th># of Programs<br />(% of all Programs)</th><th>Program Obligations<br />(% of all Obligations)</th></tr>
            </thead>
            <tbody>
                <tr><td>2008</td><td>559 (35%)</td><td>$1.35 trillion (71.78%)</td></tr>
                <tr class="even"><td>2009</td><td>583 (34%)</td><td>$1.01 trillion (60.75%)</td></tr>
                <tr><td>2010</td><td>531 (33%)</td><td>$435.53 billion (30.50%)</td></tr>
            </tbody>
        </table>
<p>Despite the pervasiveness of reporting errors, a significant number of programs report obligations figures to both the CFDA and USASpending.gov that are consistent with one another. In fact, over the past three years the percentage of all programs that report consistently has hovered around 33%, or one-third of all programs. However, between FY2008 and FY2010, the overall percentage of consistently reported obligations appears to have decreased. A similar trend was apparent in our last run of this analysis, which covered FY2007-FY2009. This is most likely due to the high latency that we have observed in the reporting to USASpending.gov.</p>
<p>In all three years examined, at least one-third of all programs reported obligations consistently.  262 programs reported consistently for all three of these years. The agencies with the highest number of consistently reporting programs were the Department of Health and Human Services (110), the Department of Education (44) and the Department of Agriculture (25). </p>

        <h4>Completeness</h4>
        <p>Tracking where the money goes is just as important as tracking how much was spent. The FFATA requires that data regarding the recipient, location, agency and CFDA program of each obligation be reported. However, these fields suffer from serious data quality problems. For each year between 2008 and 2010, at least 50% of all obligations were incompletely reported.</p>
    	<h5 class="table-header">Spending Incompletely Reported by Fiscal Year</h5>
		<table class="results-table">
            <thead>
    		    <tr><th>Fiscal Year</th><th>Failed Spending for Completeness</th><th>Total Spending</th><th>% Failed Completeness</th></tr>
            </thead>
            <tbody>
    			<tr><td>2008</td><td>$1,455,055,450,288</td><td>$1,852,452,110,821</td><td>78.55%</td></tr>
	    		<tr class="even"><td>2009</td><td>$952,058,362,968</td><td>$1,621,109,941,736</td><td>58.73%</td></tr>
		    	<tr><td>2010</td><td>$951,739,782,465</td><td>$1,381,784,887,564</td><td>68.88%</td></tr>
            </tbody>
		</table>
        <p>In addition to incomplete and poorly formatted fields, there is another class of error that we have no way of programmatically measuring. Many of the descriptive fields, such as those that describe the purpose of the grant, appear to be a random mix of letters and numbers. Because we have no way of quantifying these descriptive errors, the above percentages represent the lower bound of completion errors in USASpending.gov. It is possible that the actual error rate is substantially higher.</p>

    <h4>Conclusion</h4>
    <p>Because USASpending.gov is based on datasets that are widely accepted as flawed or incomplete, the data on the site can only be as good as the data in the Federal Assistance Award Data System (FAADS Plus) or the Federal Procurement Data System (FPDS-NG) – the underlying reporting systems. USASpending.gov must fix the way agencies report program spending to these systems. One path to improvement would be to institute meaningful oversight. According to a GAO report, the Office of Management and Budget (OMB) has no process for tracking down programs that do not report at all. The data in Clearspending makes it possible for anyone to find both nonreporting programs and those programs with an excellent reporting record. Highlighting programs and agencies on both ends of the spectrum is the first step to identifying best practices and pitfalls of federal spending reporting.</p>
        
</div>
    <div id="rtColumn">
        <div id="reporting">
            <h3>How does the federal government report its spending?</h3>
            <p>The flow of federal spending reporting can get complicated. We've tried to simplify it for you with a <a href="{% url animation %}">step-by-step visualization</a>.</p> 
        </div>
        <div id="metrics">
            <h3>Our Metrics</h3>
            <p class="no-border">How did we conduct our analysis and what assumptions did we make? What limitations exist with the comparison data we're using? We measured the data across three categories:</p>
            <ul>
                <li><strong>Consistency</strong>: A comparison of CFDA obligations and USASpending.gov obligations.</li>
                <li><strong>Completeness</strong>: A measure of how many required fields are completed. </li>
                <li><strong>Timeliness</strong>: A measure of how quickly obligations were reported.</li>
            </ul>
           <p class="no-border">See our <a href="{% url methodology %}">methodology</a> for more information.</p>
        </div>
    </div> 
    <div class="clear"></div>   
</div>

{% endblock %}
